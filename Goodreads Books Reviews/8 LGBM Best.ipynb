{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "from wandb.lightgbm import wandb_callback, log_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33md-a-pop\u001b[0m (\u001b[33mmidigpt\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retraining model with best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_data():\n",
    "    # read and prepare data for training\n",
    "    train = pd.read_csv(\"train.csv\")\n",
    "    val = pd.read_csv(\"val.csv\")\n",
    "\n",
    "    train['user_id'] = train['user_id'].astype(\"category\")\n",
    "    train['review_id'] = train['review_id'].astype(\"category\")\n",
    "    train['book_id'] = train['book_id'].astype(\"category\")\n",
    "    train = train.drop(\"review_text\", axis=1)\n",
    "\n",
    "    val['user_id'] = val['user_id'].astype(\"category\")\n",
    "    val['review_id'] = val['review_id'].astype(\"category\")\n",
    "    val['book_id'] = val['book_id'].astype(\"category\")\n",
    "    val = val.drop(\"review_text\", axis=1)\n",
    "    \n",
    "    return train, val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_macroF1_lgb(truth, predictions):  \n",
    "    # this follows the discussion in https://github.com/Microsoft/LightGBM/issues/1483\n",
    "    pred_labels = predictions.reshape(len(np.unique(truth)),-1).argmax(axis=0)\n",
    "    f1 = f1_score(truth, pred_labels, average='macro')\n",
    "    return ('macroF1', f1, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(config):\n",
    "    # perform one training iteration\n",
    "    train, val = parse_data()\n",
    "    \n",
    "    model = lgb.LGBMClassifier(boosting_type=config[\"boosting_type\"], num_leaves=config[\"num_leaves\"], \n",
    "                               max_depth=config[\"max_depth\"], learning_rate=config[\"learning_rate\"], \n",
    "                               n_estimators=config[\"n_estimators\"], min_child_samples=config[\"min_child_samples\"], \n",
    "                               subsample=config[\"subsample\"], colsample_bytree=config[\"colsample_bytree\"], \n",
    "                               random_state=config[\"random_state\"], reg_alpha=config[\"reg_alpha\"], \n",
    "                               reg_lambda=config[\"reg_lambda\"])\n",
    "    \n",
    "    train_config = model.get_params()\n",
    "    print(\"TRAIN CONFIG\")\n",
    "    print(train_config)\n",
    "    \n",
    "    run = wandb.init(project=\"Goodreads Books Reviews\", entity=\"d-a-pop\", job_type=\"training\", config=train_config)    \n",
    "    \n",
    "    gbm = model.fit(train.drop(\"rating\", axis=1), train[\"rating\"], callbacks=[wandb_callback()], \\\n",
    "                     categorical_feature=[\"user_id\", \"book_id\", \"review_id\"], eval_metric=evaluate_macroF1_lgb, \\\n",
    "                     eval_set=[(train.drop(\"rating\", axis=1), train[\"rating\"]), (val.drop(\"rating\", axis=1), val[\"rating\"])], \\\n",
    "                     eval_names=[\"training\", \"validation\"]);\n",
    "\n",
    "    log_summary(gbm.booster_)\n",
    "    \n",
    "    if config[\"log_preds\"]:\n",
    "        ypred_ = model.predict_proba(val.drop(\"rating\", axis=1))\n",
    "        predictions = val[[\"review_id\", \"rating\"]]\n",
    "        predictions[\"pred\"] = np.argmax(ypred_, axis=1)\n",
    "        table = wandb.Table(dataframe=predictions)\n",
    "        wandb.log({\"pred_table\":table})\n",
    "    \n",
    "    run.finish()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"log_preds\":True, \"boosting_type\":\"gbdt\", \"num_leaves\":41, \"max_depth\":-1, \"learning_rate\":0.1, \n",
    "     \"n_estimators\":300, \"min_child_samples\":20, \"subsample\":1.0, \"colsample_bytree\":1.0, \"random_state\":42, \n",
    "     \"reg_alpha\":0, \"reg_lambda\":0.01}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val = parse_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lgb.LGBMClassifier(boosting_type=config[\"boosting_type\"], num_leaves=config[\"num_leaves\"], \n",
    "                               max_depth=config[\"max_depth\"], learning_rate=config[\"learning_rate\"], \n",
    "                               n_estimators=config[\"n_estimators\"], min_child_samples=config[\"min_child_samples\"], \n",
    "                               subsample=config[\"subsample\"], colsample_bytree=config[\"colsample_bytree\"], \n",
    "                               random_state=config[\"random_state\"], reg_alpha=config[\"reg_alpha\"], \n",
    "                               reg_lambda=config[\"reg_lambda\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN CONFIG\n",
      "{'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 300, 'n_jobs': -1, 'num_leaves': 41, 'objective': None, 'random_state': 42, 'reg_alpha': 0, 'reg_lambda': 0.01, 'silent': True, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}\n"
     ]
    }
   ],
   "source": [
    "train_config = model.get_params()\n",
    "print(\"TRAIN CONFIG\")\n",
    "print(train_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33md-a-pop\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/dragos/Downloads/wandb/run-20230331_151957-qadyid3n</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/d-a-pop/Goodreads%20Books%20Reviews/runs/qadyid3n' target=\"_blank\">exalted-valley-72</a></strong> to <a href='https://wandb.ai/d-a-pop/Goodreads%20Books%20Reviews' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/d-a-pop/Goodreads%20Books%20Reviews' target=\"_blank\">https://wandb.ai/d-a-pop/Goodreads%20Books%20Reviews</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/d-a-pop/Goodreads%20Books%20Reviews/runs/qadyid3n' target=\"_blank\">https://wandb.ai/d-a-pop/Goodreads%20Books%20Reviews/runs/qadyid3n</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = wandb.init(project=\"Goodreads Books Reviews\", entity=\"d-a-pop\", job_type=\"training\", config=train_config)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dragos/anaconda3/envs/lgbm/lib/python3.8/site-packages/lightgbm/basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "/Users/dragos/anaconda3/envs/lgbm/lib/python3.8/site-packages/lightgbm/basic.py:1554: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is ['book_id', 'review_id', 'user_id']\n",
      "  warnings.warn('categorical_feature in Dataset is overridden.\\n'\n",
      "/Users/dragos/anaconda3/envs/lgbm/lib/python3.8/site-packages/lightgbm/basic.py:1286: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  warnings.warn('Overriding the parameters from Reference Dataset.')\n",
      "/Users/dragos/anaconda3/envs/lgbm/lib/python3.8/site-packages/lightgbm/basic.py:1098: UserWarning: categorical_column in param dict is overridden.\n",
      "  warnings.warn('{} in param dict is overridden.'.format(cat_alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's multi_logloss: 1.43777\ttraining's macroF1: 0.13197\tvalidation's multi_logloss: 1.43742\tvalidation's macroF1: 0.128805\n",
      "[2]\ttraining's multi_logloss: 1.413\ttraining's macroF1: 0.179453\tvalidation's multi_logloss: 1.41626\tvalidation's macroF1: 0.173828\n",
      "[3]\ttraining's multi_logloss: 1.3942\ttraining's macroF1: 0.201963\tvalidation's multi_logloss: 1.40039\tvalidation's macroF1: 0.192632\n",
      "[4]\ttraining's multi_logloss: 1.37848\ttraining's macroF1: 0.218282\tvalidation's multi_logloss: 1.38768\tvalidation's macroF1: 0.206907\n",
      "[5]\ttraining's multi_logloss: 1.36474\ttraining's macroF1: 0.24253\tvalidation's multi_logloss: 1.37642\tvalidation's macroF1: 0.24176\n",
      "[6]\ttraining's multi_logloss: 1.35337\ttraining's macroF1: 0.259152\tvalidation's multi_logloss: 1.36773\tvalidation's macroF1: 0.252373\n",
      "[7]\ttraining's multi_logloss: 1.34305\ttraining's macroF1: 0.270527\tvalidation's multi_logloss: 1.36097\tvalidation's macroF1: 0.259668\n",
      "[8]\ttraining's multi_logloss: 1.33375\ttraining's macroF1: 0.280347\tvalidation's multi_logloss: 1.35405\tvalidation's macroF1: 0.265684\n",
      "[9]\ttraining's multi_logloss: 1.32528\ttraining's macroF1: 0.289805\tvalidation's multi_logloss: 1.34909\tvalidation's macroF1: 0.270376\n",
      "[10]\ttraining's multi_logloss: 1.31755\ttraining's macroF1: 0.299137\tvalidation's multi_logloss: 1.34365\tvalidation's macroF1: 0.277614\n",
      "[11]\ttraining's multi_logloss: 1.31003\ttraining's macroF1: 0.306357\tvalidation's multi_logloss: 1.33826\tvalidation's macroF1: 0.281942\n",
      "[12]\ttraining's multi_logloss: 1.30307\ttraining's macroF1: 0.312857\tvalidation's multi_logloss: 1.33379\tvalidation's macroF1: 0.287526\n",
      "[13]\ttraining's multi_logloss: 1.2964\ttraining's macroF1: 0.319364\tvalidation's multi_logloss: 1.32927\tvalidation's macroF1: 0.292779\n",
      "[14]\ttraining's multi_logloss: 1.29034\ttraining's macroF1: 0.325361\tvalidation's multi_logloss: 1.32522\tvalidation's macroF1: 0.297443\n",
      "[15]\ttraining's multi_logloss: 1.28432\ttraining's macroF1: 0.331426\tvalidation's multi_logloss: 1.3215\tvalidation's macroF1: 0.299769\n",
      "[16]\ttraining's multi_logloss: 1.27854\ttraining's macroF1: 0.336714\tvalidation's multi_logloss: 1.31817\tvalidation's macroF1: 0.303677\n",
      "[17]\ttraining's multi_logloss: 1.27292\ttraining's macroF1: 0.341887\tvalidation's multi_logloss: 1.31472\tvalidation's macroF1: 0.307698\n",
      "[18]\ttraining's multi_logloss: 1.26754\ttraining's macroF1: 0.346537\tvalidation's multi_logloss: 1.31151\tvalidation's macroF1: 0.309676\n",
      "[19]\ttraining's multi_logloss: 1.26261\ttraining's macroF1: 0.351128\tvalidation's multi_logloss: 1.3085\tvalidation's macroF1: 0.312493\n",
      "[20]\ttraining's multi_logloss: 1.2577\ttraining's macroF1: 0.355489\tvalidation's multi_logloss: 1.30571\tvalidation's macroF1: 0.314687\n",
      "[21]\ttraining's multi_logloss: 1.25328\ttraining's macroF1: 0.359752\tvalidation's multi_logloss: 1.30347\tvalidation's macroF1: 0.316869\n",
      "[22]\ttraining's multi_logloss: 1.24891\ttraining's macroF1: 0.363591\tvalidation's multi_logloss: 1.30132\tvalidation's macroF1: 0.31769\n",
      "[23]\ttraining's multi_logloss: 1.24457\ttraining's macroF1: 0.367346\tvalidation's multi_logloss: 1.29891\tvalidation's macroF1: 0.320545\n",
      "[24]\ttraining's multi_logloss: 1.24045\ttraining's macroF1: 0.370915\tvalidation's multi_logloss: 1.29644\tvalidation's macroF1: 0.32268\n",
      "[25]\ttraining's multi_logloss: 1.23653\ttraining's macroF1: 0.374799\tvalidation's multi_logloss: 1.29428\tvalidation's macroF1: 0.324314\n",
      "[26]\ttraining's multi_logloss: 1.23274\ttraining's macroF1: 0.378085\tvalidation's multi_logloss: 1.29208\tvalidation's macroF1: 0.325687\n",
      "[27]\ttraining's multi_logloss: 1.22903\ttraining's macroF1: 0.381835\tvalidation's multi_logloss: 1.29019\tvalidation's macroF1: 0.327872\n",
      "[28]\ttraining's multi_logloss: 1.22541\ttraining's macroF1: 0.385261\tvalidation's multi_logloss: 1.28855\tvalidation's macroF1: 0.330083\n",
      "[29]\ttraining's multi_logloss: 1.22187\ttraining's macroF1: 0.38897\tvalidation's multi_logloss: 1.28674\tvalidation's macroF1: 0.331328\n",
      "[30]\ttraining's multi_logloss: 1.2183\ttraining's macroF1: 0.392164\tvalidation's multi_logloss: 1.28494\tvalidation's macroF1: 0.333109\n",
      "[31]\ttraining's multi_logloss: 1.21506\ttraining's macroF1: 0.394941\tvalidation's multi_logloss: 1.28345\tvalidation's macroF1: 0.33476\n",
      "[32]\ttraining's multi_logloss: 1.21174\ttraining's macroF1: 0.398091\tvalidation's multi_logloss: 1.28177\tvalidation's macroF1: 0.336952\n",
      "[33]\ttraining's multi_logloss: 1.20838\ttraining's macroF1: 0.401165\tvalidation's multi_logloss: 1.27998\tvalidation's macroF1: 0.339955\n",
      "[34]\ttraining's multi_logloss: 1.20529\ttraining's macroF1: 0.403804\tvalidation's multi_logloss: 1.27831\tvalidation's macroF1: 0.34146\n",
      "[35]\ttraining's multi_logloss: 1.20233\ttraining's macroF1: 0.406124\tvalidation's multi_logloss: 1.27685\tvalidation's macroF1: 0.343057\n",
      "[36]\ttraining's multi_logloss: 1.1994\ttraining's macroF1: 0.408747\tvalidation's multi_logloss: 1.27549\tvalidation's macroF1: 0.343781\n",
      "[37]\ttraining's multi_logloss: 1.19648\ttraining's macroF1: 0.411293\tvalidation's multi_logloss: 1.27417\tvalidation's macroF1: 0.345309\n",
      "[38]\ttraining's multi_logloss: 1.19372\ttraining's macroF1: 0.414068\tvalidation's multi_logloss: 1.2729\tvalidation's macroF1: 0.346389\n",
      "[39]\ttraining's multi_logloss: 1.19096\ttraining's macroF1: 0.416521\tvalidation's multi_logloss: 1.27173\tvalidation's macroF1: 0.347927\n",
      "[40]\ttraining's multi_logloss: 1.18831\ttraining's macroF1: 0.418882\tvalidation's multi_logloss: 1.27062\tvalidation's macroF1: 0.349139\n",
      "[41]\ttraining's multi_logloss: 1.1858\ttraining's macroF1: 0.421075\tvalidation's multi_logloss: 1.26954\tvalidation's macroF1: 0.350231\n",
      "[42]\ttraining's multi_logloss: 1.18318\ttraining's macroF1: 0.423638\tvalidation's multi_logloss: 1.26852\tvalidation's macroF1: 0.351659\n",
      "[43]\ttraining's multi_logloss: 1.18062\ttraining's macroF1: 0.426082\tvalidation's multi_logloss: 1.26737\tvalidation's macroF1: 0.353169\n",
      "[44]\ttraining's multi_logloss: 1.17813\ttraining's macroF1: 0.428133\tvalidation's multi_logloss: 1.26628\tvalidation's macroF1: 0.353954\n",
      "[45]\ttraining's multi_logloss: 1.17562\ttraining's macroF1: 0.430465\tvalidation's multi_logloss: 1.26526\tvalidation's macroF1: 0.354712\n",
      "[46]\ttraining's multi_logloss: 1.17334\ttraining's macroF1: 0.432766\tvalidation's multi_logloss: 1.2643\tvalidation's macroF1: 0.355693\n",
      "[47]\ttraining's multi_logloss: 1.17099\ttraining's macroF1: 0.435228\tvalidation's multi_logloss: 1.26338\tvalidation's macroF1: 0.356762\n",
      "[48]\ttraining's multi_logloss: 1.16879\ttraining's macroF1: 0.437253\tvalidation's multi_logloss: 1.26249\tvalidation's macroF1: 0.357667\n",
      "[49]\ttraining's multi_logloss: 1.16663\ttraining's macroF1: 0.439158\tvalidation's multi_logloss: 1.26161\tvalidation's macroF1: 0.358661\n",
      "[50]\ttraining's multi_logloss: 1.1643\ttraining's macroF1: 0.441154\tvalidation's multi_logloss: 1.26078\tvalidation's macroF1: 0.359367\n",
      "[51]\ttraining's multi_logloss: 1.16203\ttraining's macroF1: 0.442903\tvalidation's multi_logloss: 1.25991\tvalidation's macroF1: 0.360442\n",
      "[52]\ttraining's multi_logloss: 1.16014\ttraining's macroF1: 0.44472\tvalidation's multi_logloss: 1.25916\tvalidation's macroF1: 0.361363\n",
      "[53]\ttraining's multi_logloss: 1.15801\ttraining's macroF1: 0.446636\tvalidation's multi_logloss: 1.25836\tvalidation's macroF1: 0.36166\n",
      "[54]\ttraining's multi_logloss: 1.1561\ttraining's macroF1: 0.448079\tvalidation's multi_logloss: 1.2576\tvalidation's macroF1: 0.362504\n",
      "[55]\ttraining's multi_logloss: 1.15421\ttraining's macroF1: 0.449594\tvalidation's multi_logloss: 1.25687\tvalidation's macroF1: 0.363894\n",
      "[56]\ttraining's multi_logloss: 1.15209\ttraining's macroF1: 0.451393\tvalidation's multi_logloss: 1.25606\tvalidation's macroF1: 0.36453\n",
      "[57]\ttraining's multi_logloss: 1.15008\ttraining's macroF1: 0.453318\tvalidation's multi_logloss: 1.2554\tvalidation's macroF1: 0.364849\n",
      "[58]\ttraining's multi_logloss: 1.14816\ttraining's macroF1: 0.455121\tvalidation's multi_logloss: 1.25476\tvalidation's macroF1: 0.365546\n",
      "[59]\ttraining's multi_logloss: 1.14621\ttraining's macroF1: 0.45707\tvalidation's multi_logloss: 1.25408\tvalidation's macroF1: 0.365932\n",
      "[60]\ttraining's multi_logloss: 1.14432\ttraining's macroF1: 0.458602\tvalidation's multi_logloss: 1.25335\tvalidation's macroF1: 0.366548\n",
      "[61]\ttraining's multi_logloss: 1.1423\ttraining's macroF1: 0.460511\tvalidation's multi_logloss: 1.25268\tvalidation's macroF1: 0.366712\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[62]\ttraining's multi_logloss: 1.14039\ttraining's macroF1: 0.462003\tvalidation's multi_logloss: 1.25193\tvalidation's macroF1: 0.367791\n",
      "[63]\ttraining's multi_logloss: 1.13865\ttraining's macroF1: 0.463457\tvalidation's multi_logloss: 1.25136\tvalidation's macroF1: 0.368376\n",
      "[64]\ttraining's multi_logloss: 1.13698\ttraining's macroF1: 0.464825\tvalidation's multi_logloss: 1.2507\tvalidation's macroF1: 0.369024\n",
      "[65]\ttraining's multi_logloss: 1.13528\ttraining's macroF1: 0.466186\tvalidation's multi_logloss: 1.25012\tvalidation's macroF1: 0.370167\n",
      "[66]\ttraining's multi_logloss: 1.13368\ttraining's macroF1: 0.467637\tvalidation's multi_logloss: 1.24954\tvalidation's macroF1: 0.369942\n",
      "[67]\ttraining's multi_logloss: 1.13218\ttraining's macroF1: 0.468953\tvalidation's multi_logloss: 1.24906\tvalidation's macroF1: 0.370709\n",
      "[68]\ttraining's multi_logloss: 1.13035\ttraining's macroF1: 0.470562\tvalidation's multi_logloss: 1.24867\tvalidation's macroF1: 0.371261\n",
      "[69]\ttraining's multi_logloss: 1.12854\ttraining's macroF1: 0.472078\tvalidation's multi_logloss: 1.24822\tvalidation's macroF1: 0.371487\n",
      "[70]\ttraining's multi_logloss: 1.12699\ttraining's macroF1: 0.473325\tvalidation's multi_logloss: 1.24767\tvalidation's macroF1: 0.372413\n",
      "[71]\ttraining's multi_logloss: 1.12524\ttraining's macroF1: 0.474789\tvalidation's multi_logloss: 1.24716\tvalidation's macroF1: 0.373471\n",
      "[72]\ttraining's multi_logloss: 1.12366\ttraining's macroF1: 0.476168\tvalidation's multi_logloss: 1.2467\tvalidation's macroF1: 0.374006\n",
      "[73]\ttraining's multi_logloss: 1.12203\ttraining's macroF1: 0.477654\tvalidation's multi_logloss: 1.24637\tvalidation's macroF1: 0.374388\n",
      "[74]\ttraining's multi_logloss: 1.1205\ttraining's macroF1: 0.479155\tvalidation's multi_logloss: 1.24589\tvalidation's macroF1: 0.374431\n",
      "[75]\ttraining's multi_logloss: 1.11897\ttraining's macroF1: 0.48033\tvalidation's multi_logloss: 1.2454\tvalidation's macroF1: 0.375056\n",
      "[76]\ttraining's multi_logloss: 1.11745\ttraining's macroF1: 0.481856\tvalidation's multi_logloss: 1.24496\tvalidation's macroF1: 0.375373\n",
      "[77]\ttraining's multi_logloss: 1.11607\ttraining's macroF1: 0.483036\tvalidation's multi_logloss: 1.24456\tvalidation's macroF1: 0.375872\n",
      "[78]\ttraining's multi_logloss: 1.11462\ttraining's macroF1: 0.484427\tvalidation's multi_logloss: 1.24412\tvalidation's macroF1: 0.376456\n",
      "[79]\ttraining's multi_logloss: 1.11308\ttraining's macroF1: 0.486017\tvalidation's multi_logloss: 1.24358\tvalidation's macroF1: 0.377089\n",
      "[80]\ttraining's multi_logloss: 1.11176\ttraining's macroF1: 0.486984\tvalidation's multi_logloss: 1.24323\tvalidation's macroF1: 0.377394\n",
      "[81]\ttraining's multi_logloss: 1.11029\ttraining's macroF1: 0.488184\tvalidation's multi_logloss: 1.24274\tvalidation's macroF1: 0.377993\n",
      "[82]\ttraining's multi_logloss: 1.10873\ttraining's macroF1: 0.489668\tvalidation's multi_logloss: 1.24224\tvalidation's macroF1: 0.378606\n",
      "[83]\ttraining's multi_logloss: 1.10721\ttraining's macroF1: 0.491\tvalidation's multi_logloss: 1.24196\tvalidation's macroF1: 0.379002\n",
      "[84]\ttraining's multi_logloss: 1.10589\ttraining's macroF1: 0.491968\tvalidation's multi_logloss: 1.24156\tvalidation's macroF1: 0.378909\n",
      "[85]\ttraining's multi_logloss: 1.10455\ttraining's macroF1: 0.492938\tvalidation's multi_logloss: 1.2411\tvalidation's macroF1: 0.379193\n",
      "[86]\ttraining's multi_logloss: 1.10303\ttraining's macroF1: 0.494348\tvalidation's multi_logloss: 1.24083\tvalidation's macroF1: 0.379402\n",
      "[87]\ttraining's multi_logloss: 1.10178\ttraining's macroF1: 0.495428\tvalidation's multi_logloss: 1.24051\tvalidation's macroF1: 0.379874\n",
      "[88]\ttraining's multi_logloss: 1.1004\ttraining's macroF1: 0.496565\tvalidation's multi_logloss: 1.2402\tvalidation's macroF1: 0.380976\n",
      "[89]\ttraining's multi_logloss: 1.09892\ttraining's macroF1: 0.497798\tvalidation's multi_logloss: 1.23993\tvalidation's macroF1: 0.381295\n",
      "[90]\ttraining's multi_logloss: 1.09769\ttraining's macroF1: 0.498676\tvalidation's multi_logloss: 1.23958\tvalidation's macroF1: 0.381581\n",
      "[91]\ttraining's multi_logloss: 1.09645\ttraining's macroF1: 0.499754\tvalidation's multi_logloss: 1.2392\tvalidation's macroF1: 0.381742\n",
      "[92]\ttraining's multi_logloss: 1.09508\ttraining's macroF1: 0.50078\tvalidation's multi_logloss: 1.23895\tvalidation's macroF1: 0.382288\n",
      "[93]\ttraining's multi_logloss: 1.09369\ttraining's macroF1: 0.501835\tvalidation's multi_logloss: 1.23868\tvalidation's macroF1: 0.382865\n",
      "[94]\ttraining's multi_logloss: 1.09251\ttraining's macroF1: 0.502982\tvalidation's multi_logloss: 1.2384\tvalidation's macroF1: 0.383479\n",
      "[95]\ttraining's multi_logloss: 1.0914\ttraining's macroF1: 0.503942\tvalidation's multi_logloss: 1.23818\tvalidation's macroF1: 0.383471\n",
      "[96]\ttraining's multi_logloss: 1.0901\ttraining's macroF1: 0.505034\tvalidation's multi_logloss: 1.23784\tvalidation's macroF1: 0.38445\n",
      "[97]\ttraining's multi_logloss: 1.08898\ttraining's macroF1: 0.506246\tvalidation's multi_logloss: 1.23759\tvalidation's macroF1: 0.384837\n",
      "[98]\ttraining's multi_logloss: 1.08787\ttraining's macroF1: 0.507464\tvalidation's multi_logloss: 1.23742\tvalidation's macroF1: 0.385462\n",
      "[99]\ttraining's multi_logloss: 1.08675\ttraining's macroF1: 0.508679\tvalidation's multi_logloss: 1.23721\tvalidation's macroF1: 0.385112\n",
      "[100]\ttraining's multi_logloss: 1.08549\ttraining's macroF1: 0.509798\tvalidation's multi_logloss: 1.23699\tvalidation's macroF1: 0.385822\n",
      "[101]\ttraining's multi_logloss: 1.08448\ttraining's macroF1: 0.510558\tvalidation's multi_logloss: 1.23671\tvalidation's macroF1: 0.386221\n",
      "[102]\ttraining's multi_logloss: 1.08344\ttraining's macroF1: 0.51154\tvalidation's multi_logloss: 1.23656\tvalidation's macroF1: 0.386527\n",
      "[103]\ttraining's multi_logloss: 1.08225\ttraining's macroF1: 0.512578\tvalidation's multi_logloss: 1.23638\tvalidation's macroF1: 0.386672\n",
      "[104]\ttraining's multi_logloss: 1.08104\ttraining's macroF1: 0.513515\tvalidation's multi_logloss: 1.23618\tvalidation's macroF1: 0.387087\n",
      "[105]\ttraining's multi_logloss: 1.07967\ttraining's macroF1: 0.514727\tvalidation's multi_logloss: 1.2359\tvalidation's macroF1: 0.387228\n",
      "[106]\ttraining's multi_logloss: 1.07854\ttraining's macroF1: 0.515806\tvalidation's multi_logloss: 1.23567\tvalidation's macroF1: 0.387572\n",
      "[107]\ttraining's multi_logloss: 1.07747\ttraining's macroF1: 0.516836\tvalidation's multi_logloss: 1.23547\tvalidation's macroF1: 0.387643\n",
      "[108]\ttraining's multi_logloss: 1.07638\ttraining's macroF1: 0.51754\tvalidation's multi_logloss: 1.23531\tvalidation's macroF1: 0.388132\n",
      "[109]\ttraining's multi_logloss: 1.07506\ttraining's macroF1: 0.518738\tvalidation's multi_logloss: 1.23519\tvalidation's macroF1: 0.387931\n",
      "[110]\ttraining's multi_logloss: 1.07408\ttraining's macroF1: 0.519342\tvalidation's multi_logloss: 1.23493\tvalidation's macroF1: 0.387833\n",
      "[111]\ttraining's multi_logloss: 1.0729\ttraining's macroF1: 0.520586\tvalidation's multi_logloss: 1.2347\tvalidation's macroF1: 0.388149\n",
      "[112]\ttraining's multi_logloss: 1.07197\ttraining's macroF1: 0.521152\tvalidation's multi_logloss: 1.23458\tvalidation's macroF1: 0.388716\n",
      "[113]\ttraining's multi_logloss: 1.07088\ttraining's macroF1: 0.521931\tvalidation's multi_logloss: 1.23444\tvalidation's macroF1: 0.388701\n",
      "[114]\ttraining's multi_logloss: 1.06964\ttraining's macroF1: 0.522909\tvalidation's multi_logloss: 1.23415\tvalidation's macroF1: 0.389248\n",
      "[115]\ttraining's multi_logloss: 1.06863\ttraining's macroF1: 0.524008\tvalidation's multi_logloss: 1.23403\tvalidation's macroF1: 0.389308\n",
      "[116]\ttraining's multi_logloss: 1.06752\ttraining's macroF1: 0.524983\tvalidation's multi_logloss: 1.23382\tvalidation's macroF1: 0.389642\n",
      "[117]\ttraining's multi_logloss: 1.06653\ttraining's macroF1: 0.52584\tvalidation's multi_logloss: 1.23371\tvalidation's macroF1: 0.389896\n",
      "[118]\ttraining's multi_logloss: 1.06539\ttraining's macroF1: 0.526902\tvalidation's multi_logloss: 1.23358\tvalidation's macroF1: 0.390546\n",
      "[119]\ttraining's multi_logloss: 1.06432\ttraining's macroF1: 0.52774\tvalidation's multi_logloss: 1.23332\tvalidation's macroF1: 0.391116\n",
      "[120]\ttraining's multi_logloss: 1.06314\ttraining's macroF1: 0.52859\tvalidation's multi_logloss: 1.23312\tvalidation's macroF1: 0.391307\n",
      "[121]\ttraining's multi_logloss: 1.06202\ttraining's macroF1: 0.529494\tvalidation's multi_logloss: 1.23295\tvalidation's macroF1: 0.392006\n",
      "[122]\ttraining's multi_logloss: 1.061\ttraining's macroF1: 0.530228\tvalidation's multi_logloss: 1.23282\tvalidation's macroF1: 0.391964\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[123]\ttraining's multi_logloss: 1.05994\ttraining's macroF1: 0.530956\tvalidation's multi_logloss: 1.23276\tvalidation's macroF1: 0.392469\n",
      "[124]\ttraining's multi_logloss: 1.05893\ttraining's macroF1: 0.531871\tvalidation's multi_logloss: 1.23265\tvalidation's macroF1: 0.392634\n",
      "[125]\ttraining's multi_logloss: 1.05794\ttraining's macroF1: 0.532866\tvalidation's multi_logloss: 1.23248\tvalidation's macroF1: 0.392338\n",
      "[126]\ttraining's multi_logloss: 1.05712\ttraining's macroF1: 0.533634\tvalidation's multi_logloss: 1.23229\tvalidation's macroF1: 0.392533\n",
      "[127]\ttraining's multi_logloss: 1.05612\ttraining's macroF1: 0.534489\tvalidation's multi_logloss: 1.23227\tvalidation's macroF1: 0.392605\n",
      "[128]\ttraining's multi_logloss: 1.0552\ttraining's macroF1: 0.535175\tvalidation's multi_logloss: 1.2321\tvalidation's macroF1: 0.392845\n",
      "[129]\ttraining's multi_logloss: 1.0541\ttraining's macroF1: 0.536218\tvalidation's multi_logloss: 1.23202\tvalidation's macroF1: 0.392749\n",
      "[130]\ttraining's multi_logloss: 1.05328\ttraining's macroF1: 0.536878\tvalidation's multi_logloss: 1.23197\tvalidation's macroF1: 0.392995\n",
      "[131]\ttraining's multi_logloss: 1.05241\ttraining's macroF1: 0.537729\tvalidation's multi_logloss: 1.23186\tvalidation's macroF1: 0.393282\n",
      "[132]\ttraining's multi_logloss: 1.05143\ttraining's macroF1: 0.538351\tvalidation's multi_logloss: 1.23174\tvalidation's macroF1: 0.393515\n",
      "[133]\ttraining's multi_logloss: 1.05037\ttraining's macroF1: 0.539322\tvalidation's multi_logloss: 1.23164\tvalidation's macroF1: 0.393156\n",
      "[134]\ttraining's multi_logloss: 1.0494\ttraining's macroF1: 0.540187\tvalidation's multi_logloss: 1.2315\tvalidation's macroF1: 0.393061\n",
      "[135]\ttraining's multi_logloss: 1.04853\ttraining's macroF1: 0.541048\tvalidation's multi_logloss: 1.23141\tvalidation's macroF1: 0.393309\n",
      "[136]\ttraining's multi_logloss: 1.0476\ttraining's macroF1: 0.541834\tvalidation's multi_logloss: 1.23139\tvalidation's macroF1: 0.393354\n",
      "[137]\ttraining's multi_logloss: 1.04659\ttraining's macroF1: 0.542737\tvalidation's multi_logloss: 1.23122\tvalidation's macroF1: 0.393436\n",
      "[138]\ttraining's multi_logloss: 1.04553\ttraining's macroF1: 0.543412\tvalidation's multi_logloss: 1.2312\tvalidation's macroF1: 0.393719\n",
      "[139]\ttraining's multi_logloss: 1.04479\ttraining's macroF1: 0.544017\tvalidation's multi_logloss: 1.2311\tvalidation's macroF1: 0.394081\n",
      "[140]\ttraining's multi_logloss: 1.04391\ttraining's macroF1: 0.544741\tvalidation's multi_logloss: 1.23106\tvalidation's macroF1: 0.394615\n",
      "[141]\ttraining's multi_logloss: 1.04291\ttraining's macroF1: 0.545533\tvalidation's multi_logloss: 1.23108\tvalidation's macroF1: 0.394762\n",
      "[142]\ttraining's multi_logloss: 1.04197\ttraining's macroF1: 0.546408\tvalidation's multi_logloss: 1.23101\tvalidation's macroF1: 0.395211\n",
      "[143]\ttraining's multi_logloss: 1.04097\ttraining's macroF1: 0.547172\tvalidation's multi_logloss: 1.23097\tvalidation's macroF1: 0.395064\n",
      "[144]\ttraining's multi_logloss: 1.04001\ttraining's macroF1: 0.547935\tvalidation's multi_logloss: 1.23086\tvalidation's macroF1: 0.395095\n",
      "[145]\ttraining's multi_logloss: 1.03914\ttraining's macroF1: 0.548718\tvalidation's multi_logloss: 1.23079\tvalidation's macroF1: 0.395093\n",
      "[146]\ttraining's multi_logloss: 1.03812\ttraining's macroF1: 0.549585\tvalidation's multi_logloss: 1.23068\tvalidation's macroF1: 0.395136\n",
      "[147]\ttraining's multi_logloss: 1.03728\ttraining's macroF1: 0.55018\tvalidation's multi_logloss: 1.23063\tvalidation's macroF1: 0.39513\n",
      "[148]\ttraining's multi_logloss: 1.03644\ttraining's macroF1: 0.550725\tvalidation's multi_logloss: 1.2305\tvalidation's macroF1: 0.395149\n",
      "[149]\ttraining's multi_logloss: 1.03566\ttraining's macroF1: 0.551443\tvalidation's multi_logloss: 1.23042\tvalidation's macroF1: 0.39562\n",
      "[150]\ttraining's multi_logloss: 1.0349\ttraining's macroF1: 0.552171\tvalidation's multi_logloss: 1.2304\tvalidation's macroF1: 0.395589\n",
      "[151]\ttraining's multi_logloss: 1.03402\ttraining's macroF1: 0.552862\tvalidation's multi_logloss: 1.23032\tvalidation's macroF1: 0.395863\n",
      "[152]\ttraining's multi_logloss: 1.03306\ttraining's macroF1: 0.553755\tvalidation's multi_logloss: 1.23027\tvalidation's macroF1: 0.395879\n",
      "[153]\ttraining's multi_logloss: 1.03236\ttraining's macroF1: 0.55423\tvalidation's multi_logloss: 1.23027\tvalidation's macroF1: 0.395875\n",
      "[154]\ttraining's multi_logloss: 1.03158\ttraining's macroF1: 0.554833\tvalidation's multi_logloss: 1.23015\tvalidation's macroF1: 0.396153\n",
      "[155]\ttraining's multi_logloss: 1.03059\ttraining's macroF1: 0.55555\tvalidation's multi_logloss: 1.23009\tvalidation's macroF1: 0.396091\n",
      "[156]\ttraining's multi_logloss: 1.02971\ttraining's macroF1: 0.55639\tvalidation's multi_logloss: 1.23008\tvalidation's macroF1: 0.396469\n",
      "[157]\ttraining's multi_logloss: 1.02881\ttraining's macroF1: 0.557057\tvalidation's multi_logloss: 1.23001\tvalidation's macroF1: 0.396599\n",
      "[158]\ttraining's multi_logloss: 1.02806\ttraining's macroF1: 0.557651\tvalidation's multi_logloss: 1.22995\tvalidation's macroF1: 0.396818\n",
      "[159]\ttraining's multi_logloss: 1.02722\ttraining's macroF1: 0.558354\tvalidation's multi_logloss: 1.22995\tvalidation's macroF1: 0.396784\n",
      "[160]\ttraining's multi_logloss: 1.02635\ttraining's macroF1: 0.559146\tvalidation's multi_logloss: 1.22988\tvalidation's macroF1: 0.396828\n",
      "[161]\ttraining's multi_logloss: 1.02558\ttraining's macroF1: 0.559711\tvalidation's multi_logloss: 1.22984\tvalidation's macroF1: 0.39682\n",
      "[162]\ttraining's multi_logloss: 1.02473\ttraining's macroF1: 0.560505\tvalidation's multi_logloss: 1.22977\tvalidation's macroF1: 0.396877\n",
      "[163]\ttraining's multi_logloss: 1.02381\ttraining's macroF1: 0.561279\tvalidation's multi_logloss: 1.22972\tvalidation's macroF1: 0.39708\n",
      "[164]\ttraining's multi_logloss: 1.02289\ttraining's macroF1: 0.561843\tvalidation's multi_logloss: 1.2297\tvalidation's macroF1: 0.397194\n",
      "[165]\ttraining's multi_logloss: 1.02212\ttraining's macroF1: 0.562444\tvalidation's multi_logloss: 1.22963\tvalidation's macroF1: 0.397175\n",
      "[166]\ttraining's multi_logloss: 1.02138\ttraining's macroF1: 0.563002\tvalidation's multi_logloss: 1.22957\tvalidation's macroF1: 0.397385\n",
      "[167]\ttraining's multi_logloss: 1.02063\ttraining's macroF1: 0.563604\tvalidation's multi_logloss: 1.22952\tvalidation's macroF1: 0.397654\n",
      "[168]\ttraining's multi_logloss: 1.01978\ttraining's macroF1: 0.564324\tvalidation's multi_logloss: 1.22949\tvalidation's macroF1: 0.39766\n",
      "[169]\ttraining's multi_logloss: 1.01906\ttraining's macroF1: 0.564994\tvalidation's multi_logloss: 1.22946\tvalidation's macroF1: 0.397656\n",
      "[170]\ttraining's multi_logloss: 1.01819\ttraining's macroF1: 0.565629\tvalidation's multi_logloss: 1.22942\tvalidation's macroF1: 0.397729\n",
      "[171]\ttraining's multi_logloss: 1.01753\ttraining's macroF1: 0.566195\tvalidation's multi_logloss: 1.22938\tvalidation's macroF1: 0.397761\n",
      "[172]\ttraining's multi_logloss: 1.01677\ttraining's macroF1: 0.56684\tvalidation's multi_logloss: 1.22929\tvalidation's macroF1: 0.397762\n",
      "[173]\ttraining's multi_logloss: 1.0159\ttraining's macroF1: 0.567577\tvalidation's multi_logloss: 1.22926\tvalidation's macroF1: 0.398356\n",
      "[174]\ttraining's multi_logloss: 1.01511\ttraining's macroF1: 0.568311\tvalidation's multi_logloss: 1.22933\tvalidation's macroF1: 0.398748\n",
      "[175]\ttraining's multi_logloss: 1.01433\ttraining's macroF1: 0.568816\tvalidation's multi_logloss: 1.22935\tvalidation's macroF1: 0.398788\n",
      "[176]\ttraining's multi_logloss: 1.01355\ttraining's macroF1: 0.569371\tvalidation's multi_logloss: 1.22927\tvalidation's macroF1: 0.398928\n",
      "[177]\ttraining's multi_logloss: 1.01294\ttraining's macroF1: 0.569955\tvalidation's multi_logloss: 1.22924\tvalidation's macroF1: 0.398802\n",
      "[178]\ttraining's multi_logloss: 1.01218\ttraining's macroF1: 0.570608\tvalidation's multi_logloss: 1.22927\tvalidation's macroF1: 0.398775\n",
      "[179]\ttraining's multi_logloss: 1.01149\ttraining's macroF1: 0.571089\tvalidation's multi_logloss: 1.22926\tvalidation's macroF1: 0.39904\n",
      "[180]\ttraining's multi_logloss: 1.01067\ttraining's macroF1: 0.571666\tvalidation's multi_logloss: 1.22927\tvalidation's macroF1: 0.398754\n",
      "[181]\ttraining's multi_logloss: 1.00993\ttraining's macroF1: 0.572226\tvalidation's multi_logloss: 1.22928\tvalidation's macroF1: 0.398871\n",
      "[182]\ttraining's multi_logloss: 1.00922\ttraining's macroF1: 0.572821\tvalidation's multi_logloss: 1.22925\tvalidation's macroF1: 0.398722\n",
      "[183]\ttraining's multi_logloss: 1.00861\ttraining's macroF1: 0.573375\tvalidation's multi_logloss: 1.22929\tvalidation's macroF1: 0.398685\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[184]\ttraining's multi_logloss: 1.00782\ttraining's macroF1: 0.57381\tvalidation's multi_logloss: 1.22924\tvalidation's macroF1: 0.398652\n",
      "[185]\ttraining's multi_logloss: 1.00682\ttraining's macroF1: 0.574718\tvalidation's multi_logloss: 1.2292\tvalidation's macroF1: 0.398375\n",
      "[186]\ttraining's multi_logloss: 1.00613\ttraining's macroF1: 0.575348\tvalidation's multi_logloss: 1.22916\tvalidation's macroF1: 0.398887\n",
      "[187]\ttraining's multi_logloss: 1.00529\ttraining's macroF1: 0.575921\tvalidation's multi_logloss: 1.22911\tvalidation's macroF1: 0.398832\n",
      "[188]\ttraining's multi_logloss: 1.00463\ttraining's macroF1: 0.576557\tvalidation's multi_logloss: 1.22907\tvalidation's macroF1: 0.398957\n",
      "[189]\ttraining's multi_logloss: 1.00383\ttraining's macroF1: 0.577203\tvalidation's multi_logloss: 1.22913\tvalidation's macroF1: 0.399368\n",
      "[190]\ttraining's multi_logloss: 1.00311\ttraining's macroF1: 0.577653\tvalidation's multi_logloss: 1.22914\tvalidation's macroF1: 0.399456\n",
      "[191]\ttraining's multi_logloss: 1.00258\ttraining's macroF1: 0.578184\tvalidation's multi_logloss: 1.22912\tvalidation's macroF1: 0.399358\n",
      "[192]\ttraining's multi_logloss: 1.00187\ttraining's macroF1: 0.578788\tvalidation's multi_logloss: 1.22909\tvalidation's macroF1: 0.399639\n",
      "[193]\ttraining's multi_logloss: 1.00126\ttraining's macroF1: 0.57931\tvalidation's multi_logloss: 1.22902\tvalidation's macroF1: 0.399584\n",
      "[194]\ttraining's multi_logloss: 1.00049\ttraining's macroF1: 0.579694\tvalidation's multi_logloss: 1.22903\tvalidation's macroF1: 0.399534\n",
      "[195]\ttraining's multi_logloss: 0.999782\ttraining's macroF1: 0.580314\tvalidation's multi_logloss: 1.22904\tvalidation's macroF1: 0.399333\n",
      "[196]\ttraining's multi_logloss: 0.998972\ttraining's macroF1: 0.581284\tvalidation's multi_logloss: 1.22903\tvalidation's macroF1: 0.399581\n",
      "[197]\ttraining's multi_logloss: 0.998199\ttraining's macroF1: 0.581666\tvalidation's multi_logloss: 1.22903\tvalidation's macroF1: 0.399857\n",
      "[198]\ttraining's multi_logloss: 0.99744\ttraining's macroF1: 0.582204\tvalidation's multi_logloss: 1.22901\tvalidation's macroF1: 0.399684\n",
      "[199]\ttraining's multi_logloss: 0.996749\ttraining's macroF1: 0.582898\tvalidation's multi_logloss: 1.22903\tvalidation's macroF1: 0.400017\n",
      "[200]\ttraining's multi_logloss: 0.995868\ttraining's macroF1: 0.583441\tvalidation's multi_logloss: 1.22905\tvalidation's macroF1: 0.400281\n",
      "[201]\ttraining's multi_logloss: 0.994992\ttraining's macroF1: 0.584124\tvalidation's multi_logloss: 1.22907\tvalidation's macroF1: 0.400424\n",
      "[202]\ttraining's multi_logloss: 0.994186\ttraining's macroF1: 0.584719\tvalidation's multi_logloss: 1.22912\tvalidation's macroF1: 0.400569\n",
      "[203]\ttraining's multi_logloss: 0.993488\ttraining's macroF1: 0.585255\tvalidation's multi_logloss: 1.22921\tvalidation's macroF1: 0.400534\n",
      "[204]\ttraining's multi_logloss: 0.992835\ttraining's macroF1: 0.585871\tvalidation's multi_logloss: 1.22923\tvalidation's macroF1: 0.400395\n",
      "[205]\ttraining's multi_logloss: 0.99219\ttraining's macroF1: 0.586388\tvalidation's multi_logloss: 1.22921\tvalidation's macroF1: 0.400378\n",
      "[206]\ttraining's multi_logloss: 0.99166\ttraining's macroF1: 0.586676\tvalidation's multi_logloss: 1.2293\tvalidation's macroF1: 0.400713\n",
      "[207]\ttraining's multi_logloss: 0.990972\ttraining's macroF1: 0.58731\tvalidation's multi_logloss: 1.2293\tvalidation's macroF1: 0.400886\n",
      "[208]\ttraining's multi_logloss: 0.990321\ttraining's macroF1: 0.587835\tvalidation's multi_logloss: 1.22935\tvalidation's macroF1: 0.400969\n",
      "[209]\ttraining's multi_logloss: 0.989532\ttraining's macroF1: 0.588396\tvalidation's multi_logloss: 1.22937\tvalidation's macroF1: 0.400719\n",
      "[210]\ttraining's multi_logloss: 0.988971\ttraining's macroF1: 0.588771\tvalidation's multi_logloss: 1.2294\tvalidation's macroF1: 0.40073\n",
      "[211]\ttraining's multi_logloss: 0.988307\ttraining's macroF1: 0.58932\tvalidation's multi_logloss: 1.22937\tvalidation's macroF1: 0.400577\n",
      "[212]\ttraining's multi_logloss: 0.987691\ttraining's macroF1: 0.589644\tvalidation's multi_logloss: 1.22939\tvalidation's macroF1: 0.40066\n",
      "[213]\ttraining's multi_logloss: 0.986947\ttraining's macroF1: 0.590436\tvalidation's multi_logloss: 1.22944\tvalidation's macroF1: 0.40078\n",
      "[214]\ttraining's multi_logloss: 0.986241\ttraining's macroF1: 0.590863\tvalidation's multi_logloss: 1.22944\tvalidation's macroF1: 0.400888\n",
      "[215]\ttraining's multi_logloss: 0.985672\ttraining's macroF1: 0.591358\tvalidation's multi_logloss: 1.22944\tvalidation's macroF1: 0.400875\n",
      "[216]\ttraining's multi_logloss: 0.985079\ttraining's macroF1: 0.59174\tvalidation's multi_logloss: 1.22951\tvalidation's macroF1: 0.401041\n",
      "[217]\ttraining's multi_logloss: 0.984259\ttraining's macroF1: 0.59216\tvalidation's multi_logloss: 1.22954\tvalidation's macroF1: 0.401302\n",
      "[218]\ttraining's multi_logloss: 0.983651\ttraining's macroF1: 0.592717\tvalidation's multi_logloss: 1.22959\tvalidation's macroF1: 0.400985\n",
      "[219]\ttraining's multi_logloss: 0.982981\ttraining's macroF1: 0.593243\tvalidation's multi_logloss: 1.2296\tvalidation's macroF1: 0.400693\n",
      "[220]\ttraining's multi_logloss: 0.982453\ttraining's macroF1: 0.593512\tvalidation's multi_logloss: 1.22958\tvalidation's macroF1: 0.400548\n",
      "[221]\ttraining's multi_logloss: 0.981887\ttraining's macroF1: 0.593921\tvalidation's multi_logloss: 1.22965\tvalidation's macroF1: 0.400624\n",
      "[222]\ttraining's multi_logloss: 0.981156\ttraining's macroF1: 0.594429\tvalidation's multi_logloss: 1.22972\tvalidation's macroF1: 0.400717\n",
      "[223]\ttraining's multi_logloss: 0.980594\ttraining's macroF1: 0.594964\tvalidation's multi_logloss: 1.22975\tvalidation's macroF1: 0.401057\n",
      "[224]\ttraining's multi_logloss: 0.979728\ttraining's macroF1: 0.59564\tvalidation's multi_logloss: 1.22977\tvalidation's macroF1: 0.401268\n",
      "[225]\ttraining's multi_logloss: 0.978921\ttraining's macroF1: 0.596212\tvalidation's multi_logloss: 1.22982\tvalidation's macroF1: 0.401276\n",
      "[226]\ttraining's multi_logloss: 0.978363\ttraining's macroF1: 0.596813\tvalidation's multi_logloss: 1.22982\tvalidation's macroF1: 0.401385\n",
      "[227]\ttraining's multi_logloss: 0.977873\ttraining's macroF1: 0.597318\tvalidation's multi_logloss: 1.22988\tvalidation's macroF1: 0.401428\n",
      "[228]\ttraining's multi_logloss: 0.97725\ttraining's macroF1: 0.597887\tvalidation's multi_logloss: 1.2299\tvalidation's macroF1: 0.401471\n",
      "[229]\ttraining's multi_logloss: 0.976712\ttraining's macroF1: 0.598379\tvalidation's multi_logloss: 1.22992\tvalidation's macroF1: 0.401447\n",
      "[230]\ttraining's multi_logloss: 0.976034\ttraining's macroF1: 0.598901\tvalidation's multi_logloss: 1.23008\tvalidation's macroF1: 0.401589\n",
      "[231]\ttraining's multi_logloss: 0.975267\ttraining's macroF1: 0.599488\tvalidation's multi_logloss: 1.23012\tvalidation's macroF1: 0.40114\n",
      "[232]\ttraining's multi_logloss: 0.974618\ttraining's macroF1: 0.599872\tvalidation's multi_logloss: 1.23015\tvalidation's macroF1: 0.401352\n",
      "[233]\ttraining's multi_logloss: 0.973708\ttraining's macroF1: 0.600558\tvalidation's multi_logloss: 1.23019\tvalidation's macroF1: 0.401422\n",
      "[234]\ttraining's multi_logloss: 0.973137\ttraining's macroF1: 0.600887\tvalidation's multi_logloss: 1.23019\tvalidation's macroF1: 0.401517\n",
      "[235]\ttraining's multi_logloss: 0.972459\ttraining's macroF1: 0.601393\tvalidation's multi_logloss: 1.23024\tvalidation's macroF1: 0.401503\n",
      "[236]\ttraining's multi_logloss: 0.97186\ttraining's macroF1: 0.601815\tvalidation's multi_logloss: 1.23022\tvalidation's macroF1: 0.401725\n",
      "[237]\ttraining's multi_logloss: 0.971328\ttraining's macroF1: 0.602225\tvalidation's multi_logloss: 1.23027\tvalidation's macroF1: 0.401812\n",
      "[238]\ttraining's multi_logloss: 0.970579\ttraining's macroF1: 0.602941\tvalidation's multi_logloss: 1.23032\tvalidation's macroF1: 0.401619\n",
      "[239]\ttraining's multi_logloss: 0.969999\ttraining's macroF1: 0.603462\tvalidation's multi_logloss: 1.23035\tvalidation's macroF1: 0.401623\n",
      "[240]\ttraining's multi_logloss: 0.969457\ttraining's macroF1: 0.603842\tvalidation's multi_logloss: 1.23035\tvalidation's macroF1: 0.401633\n",
      "[241]\ttraining's multi_logloss: 0.968666\ttraining's macroF1: 0.60449\tvalidation's multi_logloss: 1.23039\tvalidation's macroF1: 0.401651\n",
      "[242]\ttraining's multi_logloss: 0.967961\ttraining's macroF1: 0.605103\tvalidation's multi_logloss: 1.23046\tvalidation's macroF1: 0.40195\n",
      "[243]\ttraining's multi_logloss: 0.967372\ttraining's macroF1: 0.605614\tvalidation's multi_logloss: 1.23052\tvalidation's macroF1: 0.402341\n",
      "[244]\ttraining's multi_logloss: 0.966776\ttraining's macroF1: 0.606255\tvalidation's multi_logloss: 1.23059\tvalidation's macroF1: 0.402285\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[245]\ttraining's multi_logloss: 0.966217\ttraining's macroF1: 0.606624\tvalidation's multi_logloss: 1.23069\tvalidation's macroF1: 0.402153\n",
      "[246]\ttraining's multi_logloss: 0.965559\ttraining's macroF1: 0.607071\tvalidation's multi_logloss: 1.23067\tvalidation's macroF1: 0.402473\n",
      "[247]\ttraining's multi_logloss: 0.964883\ttraining's macroF1: 0.607686\tvalidation's multi_logloss: 1.23066\tvalidation's macroF1: 0.402454\n",
      "[248]\ttraining's multi_logloss: 0.964261\ttraining's macroF1: 0.60828\tvalidation's multi_logloss: 1.23065\tvalidation's macroF1: 0.402537\n",
      "[249]\ttraining's multi_logloss: 0.963599\ttraining's macroF1: 0.608726\tvalidation's multi_logloss: 1.23066\tvalidation's macroF1: 0.402672\n",
      "[250]\ttraining's multi_logloss: 0.962839\ttraining's macroF1: 0.609341\tvalidation's multi_logloss: 1.23071\tvalidation's macroF1: 0.402639\n",
      "[251]\ttraining's multi_logloss: 0.962403\ttraining's macroF1: 0.609678\tvalidation's multi_logloss: 1.23076\tvalidation's macroF1: 0.402626\n",
      "[252]\ttraining's multi_logloss: 0.961812\ttraining's macroF1: 0.61007\tvalidation's multi_logloss: 1.23087\tvalidation's macroF1: 0.402534\n",
      "[253]\ttraining's multi_logloss: 0.961238\ttraining's macroF1: 0.610401\tvalidation's multi_logloss: 1.23096\tvalidation's macroF1: 0.402591\n",
      "[254]\ttraining's multi_logloss: 0.960728\ttraining's macroF1: 0.610864\tvalidation's multi_logloss: 1.23097\tvalidation's macroF1: 0.402701\n",
      "[255]\ttraining's multi_logloss: 0.960297\ttraining's macroF1: 0.611242\tvalidation's multi_logloss: 1.231\tvalidation's macroF1: 0.402698\n",
      "[256]\ttraining's multi_logloss: 0.959867\ttraining's macroF1: 0.611621\tvalidation's multi_logloss: 1.2311\tvalidation's macroF1: 0.402758\n",
      "[257]\ttraining's multi_logloss: 0.959164\ttraining's macroF1: 0.612002\tvalidation's multi_logloss: 1.23112\tvalidation's macroF1: 0.403025\n",
      "[258]\ttraining's multi_logloss: 0.958529\ttraining's macroF1: 0.612542\tvalidation's multi_logloss: 1.23116\tvalidation's macroF1: 0.402897\n",
      "[259]\ttraining's multi_logloss: 0.958007\ttraining's macroF1: 0.612914\tvalidation's multi_logloss: 1.23121\tvalidation's macroF1: 0.402946\n",
      "[260]\ttraining's multi_logloss: 0.957385\ttraining's macroF1: 0.613439\tvalidation's multi_logloss: 1.2313\tvalidation's macroF1: 0.403083\n",
      "[261]\ttraining's multi_logloss: 0.956659\ttraining's macroF1: 0.614054\tvalidation's multi_logloss: 1.23142\tvalidation's macroF1: 0.403028\n",
      "[262]\ttraining's multi_logloss: 0.956023\ttraining's macroF1: 0.614553\tvalidation's multi_logloss: 1.23146\tvalidation's macroF1: 0.403118\n",
      "[263]\ttraining's multi_logloss: 0.95544\ttraining's macroF1: 0.614949\tvalidation's multi_logloss: 1.2315\tvalidation's macroF1: 0.403382\n",
      "[264]\ttraining's multi_logloss: 0.954868\ttraining's macroF1: 0.615581\tvalidation's multi_logloss: 1.23155\tvalidation's macroF1: 0.403514\n",
      "[265]\ttraining's multi_logloss: 0.954267\ttraining's macroF1: 0.616167\tvalidation's multi_logloss: 1.23162\tvalidation's macroF1: 0.403433\n",
      "[266]\ttraining's multi_logloss: 0.953826\ttraining's macroF1: 0.616369\tvalidation's multi_logloss: 1.23167\tvalidation's macroF1: 0.403172\n",
      "[267]\ttraining's multi_logloss: 0.953299\ttraining's macroF1: 0.616697\tvalidation's multi_logloss: 1.23171\tvalidation's macroF1: 0.40335\n",
      "[268]\ttraining's multi_logloss: 0.952884\ttraining's macroF1: 0.617094\tvalidation's multi_logloss: 1.23173\tvalidation's macroF1: 0.40359\n",
      "[269]\ttraining's multi_logloss: 0.952355\ttraining's macroF1: 0.617442\tvalidation's multi_logloss: 1.23181\tvalidation's macroF1: 0.403465\n",
      "[270]\ttraining's multi_logloss: 0.951883\ttraining's macroF1: 0.617855\tvalidation's multi_logloss: 1.23186\tvalidation's macroF1: 0.403439\n",
      "[271]\ttraining's multi_logloss: 0.95148\ttraining's macroF1: 0.618115\tvalidation's multi_logloss: 1.2319\tvalidation's macroF1: 0.403506\n",
      "[272]\ttraining's multi_logloss: 0.950943\ttraining's macroF1: 0.618562\tvalidation's multi_logloss: 1.232\tvalidation's macroF1: 0.403672\n",
      "[273]\ttraining's multi_logloss: 0.950091\ttraining's macroF1: 0.619104\tvalidation's multi_logloss: 1.23205\tvalidation's macroF1: 0.403774\n",
      "[274]\ttraining's multi_logloss: 0.949668\ttraining's macroF1: 0.61946\tvalidation's multi_logloss: 1.2321\tvalidation's macroF1: 0.403702\n",
      "[275]\ttraining's multi_logloss: 0.949248\ttraining's macroF1: 0.619797\tvalidation's multi_logloss: 1.23216\tvalidation's macroF1: 0.404066\n",
      "[276]\ttraining's multi_logloss: 0.948723\ttraining's macroF1: 0.620227\tvalidation's multi_logloss: 1.23223\tvalidation's macroF1: 0.404126\n",
      "[277]\ttraining's multi_logloss: 0.948207\ttraining's macroF1: 0.620745\tvalidation's multi_logloss: 1.23224\tvalidation's macroF1: 0.404184\n",
      "[278]\ttraining's multi_logloss: 0.947551\ttraining's macroF1: 0.621177\tvalidation's multi_logloss: 1.23232\tvalidation's macroF1: 0.404229\n",
      "[279]\ttraining's multi_logloss: 0.947118\ttraining's macroF1: 0.621586\tvalidation's multi_logloss: 1.23241\tvalidation's macroF1: 0.404276\n",
      "[280]\ttraining's multi_logloss: 0.946566\ttraining's macroF1: 0.622023\tvalidation's multi_logloss: 1.23248\tvalidation's macroF1: 0.404353\n",
      "[281]\ttraining's multi_logloss: 0.945835\ttraining's macroF1: 0.622555\tvalidation's multi_logloss: 1.23258\tvalidation's macroF1: 0.404109\n",
      "[282]\ttraining's multi_logloss: 0.945433\ttraining's macroF1: 0.622805\tvalidation's multi_logloss: 1.23262\tvalidation's macroF1: 0.404188\n",
      "[283]\ttraining's multi_logloss: 0.944946\ttraining's macroF1: 0.623165\tvalidation's multi_logloss: 1.23265\tvalidation's macroF1: 0.404174\n",
      "[284]\ttraining's multi_logloss: 0.944346\ttraining's macroF1: 0.623609\tvalidation's multi_logloss: 1.23269\tvalidation's macroF1: 0.404565\n",
      "[285]\ttraining's multi_logloss: 0.943996\ttraining's macroF1: 0.623906\tvalidation's multi_logloss: 1.23277\tvalidation's macroF1: 0.404502\n",
      "[286]\ttraining's multi_logloss: 0.943386\ttraining's macroF1: 0.624454\tvalidation's multi_logloss: 1.23282\tvalidation's macroF1: 0.404252\n",
      "[287]\ttraining's multi_logloss: 0.942945\ttraining's macroF1: 0.624779\tvalidation's multi_logloss: 1.23288\tvalidation's macroF1: 0.404188\n",
      "[288]\ttraining's multi_logloss: 0.942255\ttraining's macroF1: 0.625253\tvalidation's multi_logloss: 1.23292\tvalidation's macroF1: 0.404375\n",
      "[289]\ttraining's multi_logloss: 0.941808\ttraining's macroF1: 0.625635\tvalidation's multi_logloss: 1.23298\tvalidation's macroF1: 0.404298\n",
      "[290]\ttraining's multi_logloss: 0.941324\ttraining's macroF1: 0.626116\tvalidation's multi_logloss: 1.23303\tvalidation's macroF1: 0.404302\n",
      "[291]\ttraining's multi_logloss: 0.940842\ttraining's macroF1: 0.626427\tvalidation's multi_logloss: 1.23302\tvalidation's macroF1: 0.404038\n",
      "[292]\ttraining's multi_logloss: 0.940399\ttraining's macroF1: 0.626824\tvalidation's multi_logloss: 1.23309\tvalidation's macroF1: 0.404125\n",
      "[293]\ttraining's multi_logloss: 0.939879\ttraining's macroF1: 0.627172\tvalidation's multi_logloss: 1.23316\tvalidation's macroF1: 0.404152\n",
      "[294]\ttraining's multi_logloss: 0.939341\ttraining's macroF1: 0.627599\tvalidation's multi_logloss: 1.23321\tvalidation's macroF1: 0.404164\n",
      "[295]\ttraining's multi_logloss: 0.938934\ttraining's macroF1: 0.627908\tvalidation's multi_logloss: 1.23322\tvalidation's macroF1: 0.404179\n",
      "[296]\ttraining's multi_logloss: 0.938429\ttraining's macroF1: 0.628344\tvalidation's multi_logloss: 1.23326\tvalidation's macroF1: 0.404414\n",
      "[297]\ttraining's multi_logloss: 0.93792\ttraining's macroF1: 0.628782\tvalidation's multi_logloss: 1.23333\tvalidation's macroF1: 0.404199\n",
      "[298]\ttraining's multi_logloss: 0.937493\ttraining's macroF1: 0.62913\tvalidation's multi_logloss: 1.2334\tvalidation's macroF1: 0.404355\n",
      "[299]\ttraining's multi_logloss: 0.937064\ttraining's macroF1: 0.629461\tvalidation's multi_logloss: 1.23348\tvalidation's macroF1: 0.40435\n",
      "[300]\ttraining's multi_logloss: 0.936658\ttraining's macroF1: 0.629742\tvalidation's multi_logloss: 1.23357\tvalidation's macroF1: 0.40421\n"
     ]
    }
   ],
   "source": [
    "gbm = model.fit(train.drop(\"rating\", axis=1), train[\"rating\"], callbacks=[wandb_callback()], \\\n",
    "                 categorical_feature=[\"user_id\", \"book_id\", \"review_id\"], eval_metric=evaluate_macroF1_lgb, \\\n",
    "                 eval_set=[(train.drop(\"rating\", axis=1), train[\"rating\"]), (val.drop(\"rating\", axis=1), val[\"rating\"])], \\\n",
    "                 eval_names=[\"training\", \"validation\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_summary(gbm.booster_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-17-1f66504940d7>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  predictions[\"pred\"] = np.argmax(ypred_, axis=1)\n"
     ]
    }
   ],
   "source": [
    "ypred_ = model.predict_proba(val.drop(\"rating\", axis=1))\n",
    "predictions = val[[\"review_id\", \"rating\"]]\n",
    "predictions[\"pred\"] = np.argmax(ypred_, axis=1)\n",
    "table = wandb.Table(dataframe=predictions)\n",
    "wandb.log({\"pred_table\":table})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>iteration</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>training_macroF1</td><td>▁▂▃▄▄▄▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇█████████</td></tr><tr><td>training_multi_logloss</td><td>█▇▆▆▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>validation_macroF1</td><td>▁▃▄▅▆▆▆▇▇▇▇▇▇▇▇▇████████████████████████</td></tr><tr><td>validation_multi_logloss</td><td>█▇▅▄▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_iteration</td><td>0</td></tr><tr><td>iteration</td><td>299</td></tr><tr><td>training_macroF1</td><td>0.62974</td></tr><tr><td>validation_macroF1</td><td>0.40421</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">exalted-valley-72</strong> at: <a href='https://wandb.ai/d-a-pop/Goodreads%20Books%20Reviews/runs/qadyid3n' target=\"_blank\">https://wandb.ai/d-a-pop/Goodreads%20Books%20Reviews/runs/qadyid3n</a><br/>Synced 6 W&B file(s), 2 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230331_151957-qadyid3n/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"test.csv\")\n",
    "r = test[\"review_id\"]\n",
    "test['user_id'] = test['user_id'].astype(\"category\")\n",
    "test['review_id'] = test['review_id'].astype(\"category\")\n",
    "test['book_id'] = test['book_id'].astype(\"category\")\n",
    "test = test.drop(\"review_text\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "478033"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = model.predict_proba(test)\n",
    "s = pd.Series(np.argmax(p, axis=1))\n",
    "len(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "478033"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5c4df7e70e9b438c761f07a4620ccb7c</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8eaeaf13213eeb16ad879a2a2591bbe5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dce649b733c153ba5363a0413cac988f</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8a46df0bb997269d6834f9437a4b0a77</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>d11d3091e22f1cf3cb865598de197599</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478028</th>\n",
       "      <td>0e1db3d4b04256f9660f5d276ddf1314</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478029</th>\n",
       "      <td>0b7f352e58caf0fd1f961e98ef04e89c</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478030</th>\n",
       "      <td>9b19eff33ddb14e9e68fca2e90379e46</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478031</th>\n",
       "      <td>8be463fed78f0da63e964706f710332b</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478032</th>\n",
       "      <td>62ed1263c7d216986cc419cd4e8a408b</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>478033 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               review_id  rating\n",
       "0       5c4df7e70e9b438c761f07a4620ccb7c       4\n",
       "1       8eaeaf13213eeb16ad879a2a2591bbe5       3\n",
       "2       dce649b733c153ba5363a0413cac988f       4\n",
       "3       8a46df0bb997269d6834f9437a4b0a77       4\n",
       "4       d11d3091e22f1cf3cb865598de197599       3\n",
       "...                                  ...     ...\n",
       "478028  0e1db3d4b04256f9660f5d276ddf1314       5\n",
       "478029  0b7f352e58caf0fd1f961e98ef04e89c       0\n",
       "478030  9b19eff33ddb14e9e68fca2e90379e46       5\n",
       "478031  8be463fed78f0da63e964706f710332b       5\n",
       "478032  62ed1263c7d216986cc419cd4e8a408b       4\n",
       "\n",
       "[478033 rows x 2 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.concat([r,s],axis=1).rename(columns={0: \"rating\"})\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"sub5.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train on train and val sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val = parse_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90000"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([train, val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "900000"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['user_id'] = df['user_id'].astype(\"category\")\n",
    "df['review_id'] = df['review_id'].astype(\"category\")\n",
    "df['book_id'] = df['book_id'].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"log_preds\":True, \"boosting_type\":\"gbdt\", \"num_leaves\":41, \"max_depth\":-1, \"learning_rate\":0.1, \n",
    "     \"n_estimators\":300, \"min_child_samples\":20, \"subsample\":1.0, \"colsample_bytree\":1.0, \"random_state\":42, \n",
    "     \"reg_alpha\":0, \"reg_lambda\":0.01}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = lgb.LGBMClassifier(boosting_type=config[\"boosting_type\"], num_leaves=config[\"num_leaves\"], \n",
    "                               max_depth=config[\"max_depth\"], learning_rate=config[\"learning_rate\"], \n",
    "                               n_estimators=config[\"n_estimators\"], min_child_samples=config[\"min_child_samples\"], \n",
    "                               subsample=config[\"subsample\"], colsample_bytree=config[\"colsample_bytree\"], \n",
    "                               random_state=config[\"random_state\"], reg_alpha=config[\"reg_alpha\"], \n",
    "                               reg_lambda=config[\"reg_lambda\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/dragos/Downloads/wandb/run-20230331_153510-3erx7212</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/d-a-pop/Goodreads%20Books%20Reviews/runs/3erx7212' target=\"_blank\">robust-rain-74</a></strong> to <a href='https://wandb.ai/d-a-pop/Goodreads%20Books%20Reviews' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/d-a-pop/Goodreads%20Books%20Reviews' target=\"_blank\">https://wandb.ai/d-a-pop/Goodreads%20Books%20Reviews</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/d-a-pop/Goodreads%20Books%20Reviews/runs/3erx7212' target=\"_blank\">https://wandb.ai/d-a-pop/Goodreads%20Books%20Reviews/runs/3erx7212</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = wandb.init(project=\"Goodreads Books Reviews\", entity=\"d-a-pop\", job_type=\"training\", config=train_config)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN CONFIG\n",
      "{'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 300, 'n_jobs': -1, 'num_leaves': 41, 'objective': None, 'random_state': 42, 'reg_alpha': 0, 'reg_lambda': 0.01, 'silent': True, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}\n"
     ]
    }
   ],
   "source": [
    "train_config = model1.get_params()\n",
    "print(\"TRAIN CONFIG\")\n",
    "print(train_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm = model1.fit(df.drop(\"rating\", axis=1), df[\"rating\"], callbacks=[wandb_callback()], \\\n",
    "                 categorical_feature=[\"user_id\", \"book_id\", \"review_id\"], eval_metric=evaluate_macroF1_lgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_summary(gbm.booster_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65606856b50c4eaf83360d74623d767e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.003 MB of 0.003 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>iteration</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_iteration</td><td>0</td></tr><tr><td>iteration</td><td>299</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">robust-rain-74</strong> at: <a href='https://wandb.ai/d-a-pop/Goodreads%20Books%20Reviews/runs/3erx7212' target=\"_blank\">https://wandb.ai/d-a-pop/Goodreads%20Books%20Reviews/runs/3erx7212</a><br/>Synced 6 W&B file(s), 1 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230331_153510-3erx7212/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"test.csv\")\n",
    "r = test[\"review_id\"]\n",
    "test['user_id'] = test['user_id'].astype(\"category\")\n",
    "test['review_id'] = test['review_id'].astype(\"category\")\n",
    "test['book_id'] = test['book_id'].astype(\"category\")\n",
    "test = test.drop(\"review_text\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "478033"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = model1.predict_proba(test)\n",
    "s = pd.Series(np.argmax(p, axis=1))\n",
    "len(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "478033"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5c4df7e70e9b438c761f07a4620ccb7c</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8eaeaf13213eeb16ad879a2a2591bbe5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dce649b733c153ba5363a0413cac988f</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8a46df0bb997269d6834f9437a4b0a77</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>d11d3091e22f1cf3cb865598de197599</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478028</th>\n",
       "      <td>0e1db3d4b04256f9660f5d276ddf1314</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478029</th>\n",
       "      <td>0b7f352e58caf0fd1f961e98ef04e89c</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478030</th>\n",
       "      <td>9b19eff33ddb14e9e68fca2e90379e46</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478031</th>\n",
       "      <td>8be463fed78f0da63e964706f710332b</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478032</th>\n",
       "      <td>62ed1263c7d216986cc419cd4e8a408b</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>478033 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               review_id  rating\n",
       "0       5c4df7e70e9b438c761f07a4620ccb7c       4\n",
       "1       8eaeaf13213eeb16ad879a2a2591bbe5       3\n",
       "2       dce649b733c153ba5363a0413cac988f       4\n",
       "3       8a46df0bb997269d6834f9437a4b0a77       4\n",
       "4       d11d3091e22f1cf3cb865598de197599       3\n",
       "...                                  ...     ...\n",
       "478028  0e1db3d4b04256f9660f5d276ddf1314       5\n",
       "478029  0b7f352e58caf0fd1f961e98ef04e89c       0\n",
       "478030  9b19eff33ddb14e9e68fca2e90379e46       5\n",
       "478031  8be463fed78f0da63e964706f710332b       5\n",
       "478032  62ed1263c7d216986cc419cd4e8a408b       4\n",
       "\n",
       "[478033 rows x 2 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.concat([r,s],axis=1).rename(columns={0: \"rating\"})\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"sub6.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
