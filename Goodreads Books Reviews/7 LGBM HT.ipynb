{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dragos/anaconda3/envs/lgbm/lib/python3.8/site-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.15) or chardet (3.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "from wandb.lightgbm import wandb_callback, log_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33md-a-pop\u001b[0m (\u001b[33mmidigpt\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_data(n):\n",
    "    # read and prepare data for training\n",
    "    train = pd.read_csv(\"train.csv\", nrows=n)\n",
    "    val = pd.read_csv(\"val.csv\", nrows=n)\n",
    "\n",
    "    train['user_id'] = train['user_id'].astype(\"category\")\n",
    "    train['review_id'] = train['review_id'].astype(\"category\")\n",
    "    train['book_id'] = train['book_id'].astype(\"category\")\n",
    "    train = train.drop(\"review_text\", axis=1)\n",
    "\n",
    "    val['user_id'] = val['user_id'].astype(\"category\")\n",
    "    val['review_id'] = val['review_id'].astype(\"category\")\n",
    "    val['book_id'] = val['book_id'].astype(\"category\")\n",
    "    val = val.drop(\"review_text\", axis=1)\n",
    "    \n",
    "    return train, val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_macroF1_lgb(truth, predictions):  \n",
    "    # this follows the discussion in https://github.com/Microsoft/LightGBM/issues/1483\n",
    "    pred_labels = predictions.reshape(len(np.unique(truth)),-1).argmax(axis=0)\n",
    "    f1 = f1_score(truth, pred_labels, average='macro')\n",
    "    return ('macroF1', f1, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(config):\n",
    "    # perform one training iteration\n",
    "    train, val = parse_data(100)\n",
    "    \n",
    "    model = lgb.LGBMClassifier(boosting_type=config[\"boosting_type\"], num_leaves=config[\"num_leaves\"], \n",
    "                               max_depth=config[\"max_depth\"], learning_rate=config[\"learning_rate\"], \n",
    "                               n_estimators=config[\"n_estimators\"], min_child_samples=config[\"min_child_samples\"], \n",
    "                               subsample=config[\"subsample\"], colsample_bytree=config[\"colsample_bytree\"], \n",
    "                               random_state=config[\"random_state\"], reg_alpha=config[\"reg_alpha\"], \n",
    "                               reg_lambda=config[\"reg_lambda\"])\n",
    "    \n",
    "    train_config = model.get_params()\n",
    "    print(\"TRAIN CONFIG\")\n",
    "    print(train_config)\n",
    "    \n",
    "    run = wandb.init(project=\"Goodreads Books Reviews\", entity=\"d-a-pop\", job_type=\"training\", config=train_config)    \n",
    "    \n",
    "    gbm = model.fit(train.drop(\"rating\", axis=1), train[\"rating\"], callbacks=[wandb_callback()], \\\n",
    "                     categorical_feature=[\"user_id\", \"book_id\", \"review_id\"], eval_metric=evaluate_macroF1_lgb, \\\n",
    "                     eval_set=[(train.drop(\"rating\", axis=1), train[\"rating\"]), (val.drop(\"rating\", axis=1), val[\"rating\"])], \\\n",
    "                     eval_names=[\"training\", \"validation\"]);\n",
    "\n",
    "    log_summary(gbm.booster_)\n",
    "    \n",
    "    if config[\"log_preds\"]:\n",
    "        ypred_ = model.predict_proba(val.drop(\"rating\", axis=1))\n",
    "        predictions = val[[\"review_id\", \"rating\"]]\n",
    "        predictions[\"pred\"] = np.argmax(ypred_, axis=1)\n",
    "        table = wandb.Table(dataframe=predictions)\n",
    "        wandb.log({\"pred_table\":table})\n",
    "    \n",
    "    run.finish()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_config = {\"log_preds\":False, \"boosting_type\":\"gbdt\", \"num_leaves\":31, \"max_depth\":-1, \"learning_rate\":0.1, \n",
    "     \"n_estimators\":100, \"min_child_samples\":20, \"subsample\":1.0, \"colsample_bytree\":1.0, \"random_state\":42, \n",
    "     \"reg_alpha\":0, \"reg_lambda\":0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33md-a-pop\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN CONFIG\n",
      "{'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 42, 'reg_alpha': 0, 'reg_lambda': 0, 'silent': True, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/dragos/Downloads/wandb/run-20230330_145646-7p1k6ziz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/d-a-pop/Goodreads%20Books%20Reviews/runs/7p1k6ziz' target=\"_blank\">legendary-star-19</a></strong> to <a href='https://wandb.ai/d-a-pop/Goodreads%20Books%20Reviews' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/d-a-pop/Goodreads%20Books%20Reviews' target=\"_blank\">https://wandb.ai/d-a-pop/Goodreads%20Books%20Reviews</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/d-a-pop/Goodreads%20Books%20Reviews/runs/7p1k6ziz' target=\"_blank\">https://wandb.ai/d-a-pop/Goodreads%20Books%20Reviews/runs/7p1k6ziz</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dragos/anaconda3/envs/lgbm/lib/python3.8/site-packages/lightgbm/basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "/Users/dragos/anaconda3/envs/lgbm/lib/python3.8/site-packages/lightgbm/basic.py:1554: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is ['book_id', 'review_id', 'user_id']\n",
      "  warnings.warn('categorical_feature in Dataset is overridden.\\n'\n",
      "/Users/dragos/anaconda3/envs/lgbm/lib/python3.8/site-packages/lightgbm/basic.py:1286: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  warnings.warn('Overriding the parameters from Reference Dataset.')\n",
      "/Users/dragos/anaconda3/envs/lgbm/lib/python3.8/site-packages/lightgbm/basic.py:1098: UserWarning: categorical_column in param dict is overridden.\n",
      "  warnings.warn('{} in param dict is overridden.'.format(cat_alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's multi_logloss: 1.46046\ttraining's macroF1: 0.131291\tvalidation's multi_logloss: 1.45455\tvalidation's macroF1: 0.114435\n",
      "[2]\ttraining's multi_logloss: 1.40053\ttraining's macroF1: 0.219698\tvalidation's multi_logloss: 1.4424\tvalidation's macroF1: 0.139367\n",
      "[3]\ttraining's multi_logloss: 1.35607\ttraining's macroF1: 0.255532\tvalidation's multi_logloss: 1.4389\tvalidation's macroF1: 0.150138\n",
      "[4]\ttraining's multi_logloss: 1.31125\ttraining's macroF1: 0.301984\tvalidation's multi_logloss: 1.43731\tvalidation's macroF1: 0.182005\n",
      "[5]\ttraining's multi_logloss: 1.27333\ttraining's macroF1: 0.300347\tvalidation's multi_logloss: 1.4401\tvalidation's macroF1: 0.184669\n",
      "[6]\ttraining's multi_logloss: 1.23517\ttraining's macroF1: 0.30904\tvalidation's multi_logloss: 1.44159\tvalidation's macroF1: 0.190694\n",
      "[7]\ttraining's multi_logloss: 1.20381\ttraining's macroF1: 0.3264\tvalidation's multi_logloss: 1.44237\tvalidation's macroF1: 0.183278\n",
      "[8]\ttraining's multi_logloss: 1.16806\ttraining's macroF1: 0.342346\tvalidation's multi_logloss: 1.44153\tvalidation's macroF1: 0.180474\n",
      "[9]\ttraining's multi_logloss: 1.13642\ttraining's macroF1: 0.393122\tvalidation's multi_logloss: 1.44591\tvalidation's macroF1: 0.242775\n",
      "[10]\ttraining's multi_logloss: 1.10484\ttraining's macroF1: 0.398499\tvalidation's multi_logloss: 1.45136\tvalidation's macroF1: 0.229872\n",
      "[11]\ttraining's multi_logloss: 1.07685\ttraining's macroF1: 0.398499\tvalidation's multi_logloss: 1.45125\tvalidation's macroF1: 0.233633\n",
      "[12]\ttraining's multi_logloss: 1.04257\ttraining's macroF1: 0.403981\tvalidation's multi_logloss: 1.45173\tvalidation's macroF1: 0.234965\n",
      "[13]\ttraining's multi_logloss: 1.01306\ttraining's macroF1: 0.398853\tvalidation's multi_logloss: 1.46602\tvalidation's macroF1: 0.242179\n",
      "[14]\ttraining's multi_logloss: 0.987508\ttraining's macroF1: 0.472556\tvalidation's multi_logloss: 1.47464\tvalidation's macroF1: 0.245617\n",
      "[15]\ttraining's multi_logloss: 0.957932\ttraining's macroF1: 0.512235\tvalidation's multi_logloss: 1.488\tvalidation's macroF1: 0.228741\n",
      "[16]\ttraining's multi_logloss: 0.933529\ttraining's macroF1: 0.55443\tvalidation's multi_logloss: 1.48815\tvalidation's macroF1: 0.225834\n",
      "[17]\ttraining's multi_logloss: 0.912053\ttraining's macroF1: 0.560002\tvalidation's multi_logloss: 1.49934\tvalidation's macroF1: 0.218376\n",
      "[18]\ttraining's multi_logloss: 0.890466\ttraining's macroF1: 0.567042\tvalidation's multi_logloss: 1.50308\tvalidation's macroF1: 0.222047\n",
      "[19]\ttraining's multi_logloss: 0.870051\ttraining's macroF1: 0.646733\tvalidation's multi_logloss: 1.51175\tvalidation's macroF1: 0.234742\n",
      "[20]\ttraining's multi_logloss: 0.851398\ttraining's macroF1: 0.646733\tvalidation's multi_logloss: 1.51802\tvalidation's macroF1: 0.22861\n",
      "[21]\ttraining's multi_logloss: 0.829903\ttraining's macroF1: 0.646733\tvalidation's multi_logloss: 1.52801\tvalidation's macroF1: 0.228816\n",
      "[22]\ttraining's multi_logloss: 0.811618\ttraining's macroF1: 0.646733\tvalidation's multi_logloss: 1.54527\tvalidation's macroF1: 0.224851\n",
      "[23]\ttraining's multi_logloss: 0.790445\ttraining's macroF1: 0.646733\tvalidation's multi_logloss: 1.55335\tvalidation's macroF1: 0.220872\n",
      "[24]\ttraining's multi_logloss: 0.773299\ttraining's macroF1: 0.761287\tvalidation's multi_logloss: 1.56101\tvalidation's macroF1: 0.217246\n",
      "[25]\ttraining's multi_logloss: 0.757298\ttraining's macroF1: 0.761287\tvalidation's multi_logloss: 1.56695\tvalidation's macroF1: 0.224851\n",
      "[26]\ttraining's multi_logloss: 0.73954\ttraining's macroF1: 0.788459\tvalidation's multi_logloss: 1.569\tvalidation's macroF1: 0.212666\n",
      "[27]\ttraining's multi_logloss: 0.720635\ttraining's macroF1: 0.81628\tvalidation's multi_logloss: 1.57804\tvalidation's macroF1: 0.216693\n",
      "[28]\ttraining's multi_logloss: 0.702596\ttraining's macroF1: 0.835375\tvalidation's multi_logloss: 1.58187\tvalidation's macroF1: 0.213226\n",
      "[29]\ttraining's multi_logloss: 0.682277\ttraining's macroF1: 0.861245\tvalidation's multi_logloss: 1.59198\tvalidation's macroF1: 0.212455\n",
      "[30]\ttraining's multi_logloss: 0.667289\ttraining's macroF1: 0.873277\tvalidation's multi_logloss: 1.59627\tvalidation's macroF1: 0.224569\n",
      "[31]\ttraining's multi_logloss: 0.654356\ttraining's macroF1: 0.911135\tvalidation's multi_logloss: 1.60008\tvalidation's macroF1: 0.216774\n",
      "[32]\ttraining's multi_logloss: 0.638783\ttraining's macroF1: 0.923638\tvalidation's multi_logloss: 1.60786\tvalidation's macroF1: 0.21958\n",
      "[33]\ttraining's multi_logloss: 0.622757\ttraining's macroF1: 0.929733\tvalidation's multi_logloss: 1.60937\tvalidation's macroF1: 0.222994\n",
      "[34]\ttraining's multi_logloss: 0.607083\ttraining's macroF1: 0.929733\tvalidation's multi_logloss: 1.62325\tvalidation's macroF1: 0.222945\n",
      "[35]\ttraining's multi_logloss: 0.590998\ttraining's macroF1: 0.929733\tvalidation's multi_logloss: 1.63083\tvalidation's macroF1: 0.219296\n",
      "[36]\ttraining's multi_logloss: 0.57716\ttraining's macroF1: 0.929733\tvalidation's multi_logloss: 1.63417\tvalidation's macroF1: 0.220647\n",
      "[37]\ttraining's multi_logloss: 0.565547\ttraining's macroF1: 0.950275\tvalidation's multi_logloss: 1.64361\tvalidation's macroF1: 0.210102\n",
      "[38]\ttraining's multi_logloss: 0.548576\ttraining's macroF1: 0.956773\tvalidation's multi_logloss: 1.6433\tvalidation's macroF1: 0.214869\n",
      "[39]\ttraining's multi_logloss: 0.537897\ttraining's macroF1: 0.956773\tvalidation's multi_logloss: 1.64692\tvalidation's macroF1: 0.198487\n",
      "[40]\ttraining's multi_logloss: 0.523575\ttraining's macroF1: 0.962753\tvalidation's multi_logloss: 1.66173\tvalidation's macroF1: 0.211438\n",
      "[41]\ttraining's multi_logloss: 0.512274\ttraining's macroF1: 0.962753\tvalidation's multi_logloss: 1.66532\tvalidation's macroF1: 0.214046\n",
      "[42]\ttraining's multi_logloss: 0.50247\ttraining's macroF1: 0.963172\tvalidation's multi_logloss: 1.66477\tvalidation's macroF1: 0.213974\n",
      "[43]\ttraining's multi_logloss: 0.490245\ttraining's macroF1: 0.969765\tvalidation's multi_logloss: 1.67327\tvalidation's macroF1: 0.210068\n",
      "[44]\ttraining's multi_logloss: 0.47986\ttraining's macroF1: 0.96277\tvalidation's multi_logloss: 1.67339\tvalidation's macroF1: 0.210068\n",
      "[45]\ttraining's multi_logloss: 0.468795\ttraining's macroF1: 0.982809\tvalidation's multi_logloss: 1.68344\tvalidation's macroF1: 0.210216\n",
      "[46]\ttraining's multi_logloss: 0.458344\ttraining's macroF1: 0.982809\tvalidation's multi_logloss: 1.6888\tvalidation's macroF1: 0.213135\n",
      "[47]\ttraining's multi_logloss: 0.447117\ttraining's macroF1: 0.988373\tvalidation's multi_logloss: 1.70694\tvalidation's macroF1: 0.217217\n",
      "[48]\ttraining's multi_logloss: 0.435453\ttraining's macroF1: 0.988373\tvalidation's multi_logloss: 1.71015\tvalidation's macroF1: 0.217217\n",
      "[49]\ttraining's multi_logloss: 0.424547\ttraining's macroF1: 0.988373\tvalidation's multi_logloss: 1.71871\tvalidation's macroF1: 0.212987\n",
      "[50]\ttraining's multi_logloss: 0.415367\ttraining's macroF1: 0.988373\tvalidation's multi_logloss: 1.7236\tvalidation's macroF1: 0.214306\n",
      "[51]\ttraining's multi_logloss: 0.407209\ttraining's macroF1: 0.994406\tvalidation's multi_logloss: 1.73874\tvalidation's macroF1: 0.210221\n",
      "[52]\ttraining's multi_logloss: 0.396673\ttraining's macroF1: 0.994406\tvalidation's multi_logloss: 1.7484\tvalidation's macroF1: 0.210494\n",
      "[53]\ttraining's multi_logloss: 0.386891\ttraining's macroF1: 0.994406\tvalidation's multi_logloss: 1.76948\tvalidation's macroF1: 0.210857\n",
      "[54]\ttraining's multi_logloss: 0.379155\ttraining's macroF1: 0.994406\tvalidation's multi_logloss: 1.77708\tvalidation's macroF1: 0.202543\n",
      "[55]\ttraining's multi_logloss: 0.370281\ttraining's macroF1: 0.994406\tvalidation's multi_logloss: 1.78141\tvalidation's macroF1: 0.200282\n",
      "[56]\ttraining's multi_logloss: 0.362149\ttraining's macroF1: 0.994406\tvalidation's multi_logloss: 1.79313\tvalidation's macroF1: 0.189376\n",
      "[57]\ttraining's multi_logloss: 0.355851\ttraining's macroF1: 0.994406\tvalidation's multi_logloss: 1.80166\tvalidation's macroF1: 0.189553\n",
      "[58]\ttraining's multi_logloss: 0.348548\ttraining's macroF1: 0.994406\tvalidation's multi_logloss: 1.80776\tvalidation's macroF1: 0.18968\n",
      "[59]\ttraining's multi_logloss: 0.341309\ttraining's macroF1: 0.994406\tvalidation's multi_logloss: 1.8231\tvalidation's macroF1: 0.183432\n",
      "[60]\ttraining's multi_logloss: 0.334529\ttraining's macroF1: 0.994406\tvalidation's multi_logloss: 1.82589\tvalidation's macroF1: 0.186016\n",
      "[61]\ttraining's multi_logloss: 0.328135\ttraining's macroF1: 0.994406\tvalidation's multi_logloss: 1.83296\tvalidation's macroF1: 0.188094\n",
      "[62]\ttraining's multi_logloss: 0.320574\ttraining's macroF1: 0.994406\tvalidation's multi_logloss: 1.83791\tvalidation's macroF1: 0.194349\n",
      "[63]\ttraining's multi_logloss: 0.313582\ttraining's macroF1: 0.994406\tvalidation's multi_logloss: 1.85226\tvalidation's macroF1: 0.188094\n",
      "[64]\ttraining's multi_logloss: 0.306684\ttraining's macroF1: 0.994406\tvalidation's multi_logloss: 1.86294\tvalidation's macroF1: 0.188094\n",
      "[65]\ttraining's multi_logloss: 0.300424\ttraining's macroF1: 0.994406\tvalidation's multi_logloss: 1.87849\tvalidation's macroF1: 0.188094\n",
      "[66]\ttraining's multi_logloss: 0.295173\ttraining's macroF1: 0.994406\tvalidation's multi_logloss: 1.87875\tvalidation's macroF1: 0.190405\n",
      "[67]\ttraining's multi_logloss: 0.289943\ttraining's macroF1: 0.994406\tvalidation's multi_logloss: 1.8841\tvalidation's macroF1: 0.190405\n",
      "[68]\ttraining's multi_logloss: 0.284324\ttraining's macroF1: 0.994406\tvalidation's multi_logloss: 1.9013\tvalidation's macroF1: 0.190446\n",
      "[69]\ttraining's multi_logloss: 0.278613\ttraining's macroF1: 0.994406\tvalidation's multi_logloss: 1.89877\tvalidation's macroF1: 0.196326\n",
      "[70]\ttraining's multi_logloss: 0.273093\ttraining's macroF1: 0.994406\tvalidation's multi_logloss: 1.90814\tvalidation's macroF1: 0.190264\n",
      "[71]\ttraining's multi_logloss: 0.267964\ttraining's macroF1: 1\tvalidation's multi_logloss: 1.91759\tvalidation's macroF1: 0.184177\n",
      "[72]\ttraining's multi_logloss: 0.263159\ttraining's macroF1: 1\tvalidation's multi_logloss: 1.92118\tvalidation's macroF1: 0.190264\n",
      "[73]\ttraining's multi_logloss: 0.257118\ttraining's macroF1: 1\tvalidation's multi_logloss: 1.93061\tvalidation's macroF1: 0.190264\n",
      "[74]\ttraining's multi_logloss: 0.251272\ttraining's macroF1: 1\tvalidation's multi_logloss: 1.93663\tvalidation's macroF1: 0.194538\n",
      "[75]\ttraining's multi_logloss: 0.247328\ttraining's macroF1: 1\tvalidation's multi_logloss: 1.95172\tvalidation's macroF1: 0.196508\n",
      "[76]\ttraining's multi_logloss: 0.242433\ttraining's macroF1: 1\tvalidation's multi_logloss: 1.95849\tvalidation's macroF1: 0.196326\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[77]\ttraining's multi_logloss: 0.238007\ttraining's macroF1: 1\tvalidation's multi_logloss: 1.96966\tvalidation's macroF1: 0.190264\n",
      "[78]\ttraining's multi_logloss: 0.231922\ttraining's macroF1: 1\tvalidation's multi_logloss: 1.97782\tvalidation's macroF1: 0.19055\n",
      "[79]\ttraining's multi_logloss: 0.227993\ttraining's macroF1: 1\tvalidation's multi_logloss: 1.99091\tvalidation's macroF1: 0.190446\n",
      "[80]\ttraining's multi_logloss: 0.223555\ttraining's macroF1: 1\tvalidation's multi_logloss: 1.99308\tvalidation's macroF1: 0.191009\n",
      "[81]\ttraining's multi_logloss: 0.218513\ttraining's macroF1: 1\tvalidation's multi_logloss: 1.99851\tvalidation's macroF1: 0.190757\n",
      "[82]\ttraining's multi_logloss: 0.214624\ttraining's macroF1: 1\tvalidation's multi_logloss: 2.00162\tvalidation's macroF1: 0.190757\n",
      "[83]\ttraining's multi_logloss: 0.210244\ttraining's macroF1: 1\tvalidation's multi_logloss: 2.01028\tvalidation's macroF1: 0.190757\n",
      "[84]\ttraining's multi_logloss: 0.206373\ttraining's macroF1: 1\tvalidation's multi_logloss: 2.0146\tvalidation's macroF1: 0.190757\n",
      "[85]\ttraining's multi_logloss: 0.202359\ttraining's macroF1: 1\tvalidation's multi_logloss: 2.03677\tvalidation's macroF1: 0.186623\n",
      "[86]\ttraining's multi_logloss: 0.198743\ttraining's macroF1: 1\tvalidation's multi_logloss: 2.04182\tvalidation's macroF1: 0.186862\n",
      "[87]\ttraining's multi_logloss: 0.194614\ttraining's macroF1: 1\tvalidation's multi_logloss: 2.04265\tvalidation's macroF1: 0.186862\n",
      "[88]\ttraining's multi_logloss: 0.191447\ttraining's macroF1: 1\tvalidation's multi_logloss: 2.04945\tvalidation's macroF1: 0.186862\n",
      "[89]\ttraining's multi_logloss: 0.187484\ttraining's macroF1: 1\tvalidation's multi_logloss: 2.05628\tvalidation's macroF1: 0.186862\n",
      "[90]\ttraining's multi_logloss: 0.183364\ttraining's macroF1: 1\tvalidation's multi_logloss: 2.07175\tvalidation's macroF1: 0.186862\n",
      "[91]\ttraining's multi_logloss: 0.180244\ttraining's macroF1: 1\tvalidation's multi_logloss: 2.07762\tvalidation's macroF1: 0.186862\n",
      "[92]\ttraining's multi_logloss: 0.176563\ttraining's macroF1: 1\tvalidation's multi_logloss: 2.08496\tvalidation's macroF1: 0.186862\n",
      "[93]\ttraining's multi_logloss: 0.173551\ttraining's macroF1: 1\tvalidation's multi_logloss: 2.08832\tvalidation's macroF1: 0.186862\n",
      "[94]\ttraining's multi_logloss: 0.170776\ttraining's macroF1: 1\tvalidation's multi_logloss: 2.09215\tvalidation's macroF1: 0.186623\n",
      "[95]\ttraining's multi_logloss: 0.167862\ttraining's macroF1: 1\tvalidation's multi_logloss: 2.09889\tvalidation's macroF1: 0.186623\n",
      "[96]\ttraining's multi_logloss: 0.1641\ttraining's macroF1: 1\tvalidation's multi_logloss: 2.1111\tvalidation's macroF1: 0.186215\n",
      "[97]\ttraining's multi_logloss: 0.161413\ttraining's macroF1: 1\tvalidation's multi_logloss: 2.11906\tvalidation's macroF1: 0.18629\n",
      "[98]\ttraining's multi_logloss: 0.158398\ttraining's macroF1: 1\tvalidation's multi_logloss: 2.1436\tvalidation's macroF1: 0.186215\n",
      "[99]\ttraining's multi_logloss: 0.15592\ttraining's macroF1: 1\tvalidation's multi_logloss: 2.14857\tvalidation's macroF1: 0.186456\n",
      "[100]\ttraining's multi_logloss: 0.152704\ttraining's macroF1: 1\tvalidation's multi_logloss: 2.16307\tvalidation's macroF1: 0.186508\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f13f7a486924459f9f26ba72394bee10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.002 MB of 0.002 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>iteration</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>training_macroF1</td><td>▁▂▂▃▃▃▄▅▅▅▆▇▇▇▇█████████████████████████</td></tr><tr><td>training_multi_logloss</td><td>█▇▇▆▆▆▅▅▅▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>validation_macroF1</td><td>▁▃▅▅██▇▇▇▇▆▆▇▇▇▆▆▆▆▆▆▆▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅</td></tr><tr><td>validation_multi_logloss</td><td>▁▁▁▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_iteration</td><td>0</td></tr><tr><td>iteration</td><td>99</td></tr><tr><td>training_macroF1</td><td>1.0</td></tr><tr><td>validation_macroF1</td><td>0.18651</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">legendary-star-19</strong> at: <a href='https://wandb.ai/d-a-pop/Goodreads%20Books%20Reviews/runs/7p1k6ziz' target=\"_blank\">https://wandb.ai/d-a-pop/Goodreads%20Books%20Reviews/runs/7p1k6ziz</a><br/>Synced 6 W&B file(s), 1 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230330_145646-7p1k6ziz/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train(default_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
